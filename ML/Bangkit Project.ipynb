{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621dffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import Augmentor\n",
    "import zipfile\n",
    "import random\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff349493",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip = 'Discoloration.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('Dataset/')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip2 = 'Periodontal.zip'\n",
    "zip_ref2    = zipfile.ZipFile(local_zip2, 'r')\n",
    "zip_ref2.extractall('Dataset/') \n",
    "zip_ref2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08689d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "417\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('Dataset/Dental Discoloration')))\n",
    "print(len(os.listdir('Dataset/Periodontal')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d7e68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AugmentData(source_dir, count):\n",
    "    source_dir = source_dir\n",
    "    output_dir = \".\"\n",
    "    p = Augmentor.Pipeline(source_directory=source_dir, output_directory=output_dir)\n",
    "    #p.random_distortion(probability=1, grid_width=4, grid_height=4, magnitude=1)\n",
    "    p.rotate(probability=0.001, max_left_rotation=0.001, max_right_rotation=0.001)\n",
    "    #p.zoom_random(probability=0.5, percentage_area=0.9)\n",
    "    #p.crop_random(probability=0.6, percentage_area=0.9)\n",
    "    #p.resize(probability=1.0, width=64, height=64)\n",
    "    p.sample(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1600659e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "The source directory you specified does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mAugmentData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDataset/Discoloration/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m AugmentData(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset/Periodontal/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m400\u001b[39m)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mAugmentData\u001b[1;34m(source_dir, count)\u001b[0m\n\u001b[0;32m      2\u001b[0m source_dir \u001b[38;5;241m=\u001b[39m source_dir\n\u001b[0;32m      3\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mAugmentor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#p.random_distortion(probability=1, grid_width=4, grid_height=4, magnitude=1)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m p\u001b[38;5;241m.\u001b[39mrotate(probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, max_left_rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, max_right_rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Bangkit\\lib\\site-packages\\Augmentor\\Pipeline.py:87\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, source_directory, output_directory, save_format)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_ground_truth_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_directory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_populate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m                   \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mground_truth_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mground_truth_output_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Bangkit\\lib\\site-packages\\Augmentor\\Pipeline.py:135\u001b[0m, in \u001b[0;36mPipeline._populate\u001b[1;34m(self, source_directory, output_directory, ground_truth_directory, ground_truth_output_directory)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Check if the source directory for the original images to augment exists at all\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(source_directory):\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe source directory you specified does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# If a ground truth directory is being specified we will check here if the path exists at all.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ground_truth_directory:\n",
      "\u001b[1;31mOSError\u001b[0m: The source directory you specified does not exist."
     ]
    }
   ],
   "source": [
    "AugmentData(\"Dataset/Discoloration/\", 1000)\n",
    "AugmentData(\"Dataset/Periodontal/\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fde6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AugmentData(\"Dataset/Healthy/\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[:testing_length]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "\n",
    "Discoloration_SOURCE_DIR = \"Dataset/Dental Discoloration/\"\n",
    "Periodontal_SOURCE_DIR = \"Dataset/Periodontal/\"\n",
    "Healthy_SOURCE_DIR = \"Dataset/Healthy/\"\n",
    "\n",
    "TRAINING_Discoloration_DIR = \"Dataset_Real/training/Dental Discoloration/\"\n",
    "TRAINING_Periodontal_DIR = \"Dataset_Real/training/Periodontal/\"\n",
    "TRAINING_Healthy_DIR = \"Dataset_Real/training/Healthy/\"\n",
    "\n",
    "TESTING_Discoloration_DIR = \"Dataset_Real/testing/Dental Discoloration/\"\n",
    "TESTING_Periodontal_DIR = \"Dataset_Real/testing/Periodontal/\"\n",
    "TESTING_Healthy_DIR = \"Dataset_Real/testing/Healthy/\"\n",
    "\n",
    "split_size = .8\n",
    "split_data(Discoloration_SOURCE_DIR, TRAINING_Discoloration_DIR, TESTING_Discoloration_DIR, split_size)\n",
    "split_data(Periodontal_SOURCE_DIR, TRAINING_Periodontal_DIR, TESTING_Periodontal_DIR, split_size)\n",
    "split_data(Healthy_SOURCE_DIR, TRAINING_Healthy_DIR, TESTING_Healthy_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea9064a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 3 classes.\n",
      "Found 240 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = \"Dataset_Real/training/\"\n",
    "# Experiment with your own parameters here to really try to drive it to 99.9% accuracy or better\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "      rotation_range=50,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=10,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(150, 150))\n",
    "\n",
    "VALIDATION_DIR = \"Dataset_Real/testing/\"\n",
    "# Experiment with your own parameters here to really try to drive it to 99.9% accuracy or better\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255,\n",
    "      rotation_range=50,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=8,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              target_size=(150, 150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 22498 images belonging to 2 classes.\n",
    "# Found 2500 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e42df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 148, 148, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 74, 74, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 72, 72, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 36, 36, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 17, 17, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 36992)             0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 36992)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               18940416  \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,054,531\n",
      "Trainable params: 19,054,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98010a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.0001), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f23b03d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 1.1148 - accuracy: 0.3781 - val_loss: 1.0503 - val_accuracy: 0.4500\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 1.0217 - accuracy: 0.5250 - val_loss: 0.9624 - val_accuracy: 0.6125\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.9005 - accuracy: 0.6031 - val_loss: 0.9533 - val_accuracy: 0.5000\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.8452 - accuracy: 0.6125 - val_loss: 0.8677 - val_accuracy: 0.5750\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 0.8804 - accuracy: 0.5938 - val_loss: 0.8156 - val_accuracy: 0.6250\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.8080 - accuracy: 0.6156 - val_loss: 0.6567 - val_accuracy: 0.6500\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 0.7390 - accuracy: 0.6812 - val_loss: 0.6821 - val_accuracy: 0.7125\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.6611 - accuracy: 0.7250 - val_loss: 0.6957 - val_accuracy: 0.6875\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.6160 - accuracy: 0.7375 - val_loss: 0.8301 - val_accuracy: 0.5750\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 0.7091 - accuracy: 0.7063 - val_loss: 0.6984 - val_accuracy: 0.6750\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 0.6029 - accuracy: 0.7250 - val_loss: 0.5433 - val_accuracy: 0.8125\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 0.5541 - accuracy: 0.7500 - val_loss: 0.6269 - val_accuracy: 0.7125\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 0.5688 - accuracy: 0.7344 - val_loss: 0.4705 - val_accuracy: 0.8250\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 0.5309 - accuracy: 0.7656 - val_loss: 0.5881 - val_accuracy: 0.7000\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.5554 - accuracy: 0.7469 - val_loss: 0.4741 - val_accuracy: 0.8250\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=32,\n",
    "                    epochs=15,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380eda8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402578c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32c633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc29996a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d005a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f282e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bangkit",
   "language": "python",
   "name": "bangkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
